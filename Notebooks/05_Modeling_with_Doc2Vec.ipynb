{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/X_doc2vec.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/y_doc2vec.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Doc2Vec Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Models/model_dbow.pkl', 'rb') as f:\n",
    "    model_dbow = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Models/model_dm_mean.pkl', 'rb') as f:\n",
    "    model_dm_mean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Models/model_dm_concat.pkl', 'rb') as f:\n",
    "    model_dm_concat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [(model_dbow, 'model_dbow'), (model_dm_mean, 'model_dm_mean'), (model_dm_concat, 'model_dm_concat')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vectors I got from the Doc2Vec models, I will fit a number of differt classifiers and evaluate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive_Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bern_nb_model_func(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    bern_nb = BernoulliNB()\n",
    "    bern_nb.fit(X_train, y_train)\n",
    "    print(\"cross-validated train scores:\", cross_val_score(bern_nb, X_train, y_train, cv=3))\n",
    "    print(\"cross-validated test scores:\", cross_val_score(bern_nb, X_test, y_test, cv=3))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10d041f60>, 'model_dbow')\n",
      "cross-validated train scores: [0.80086719 0.80195952 0.79518072]\n",
      "cross-validated test scores: [0.80684008 0.79576108 0.78640309]\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10cfa0860>, 'model_dm_mean')\n",
      "cross-validated train scores: [0.79058937 0.7902345  0.78361446]\n",
      "cross-validated test scores: [0.80684008 0.77842004 0.79074253]\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a2ec36438>, 'model_dm_concat')\n",
      "cross-validated train scores: [0.58294524 0.59058786 0.5913253 ]\n",
      "cross-validated test scores: [0.5977842  0.57996146 0.58968177]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    bern_nb_model_func(X[model[1]], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gb_model_func(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    gb = GaussianNB()\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"cross-validated train scores:\", cross_val_score(gb, X_train, y_train, cv=3))\n",
    "    print(\"cross-validated test scores:\", cross_val_score(gb, X_test, y_test, cv=3))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10d041f60>, 'model_dbow')\n",
      "cross-validated train scores: [0.84278144 0.83841953 0.84048193]\n",
      "cross-validated test scores: [0.83863198 0.83044316 0.82401157]\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10cfa0860>, 'model_dm_mean')\n",
      "cross-validated train scores: [0.79058937 0.80228076 0.8       ]\n",
      "cross-validated test scores: [0.75626204 0.76974952 0.7656702 ]\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a2ec36438>, 'model_dm_concat')\n",
      "cross-validated train scores: [0.58069696 0.58207517 0.58891566]\n",
      "cross-validated test scores: [0.56840077 0.58766859 0.57473481]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    gb_model_func(X[model[1]], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_model_func(X,y):\n",
    "    lr = LogisticRegression()\n",
    "    pipe = Pipeline([\n",
    "        ('lr', lr)\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'lr__penalty': ['l1'],\n",
    "        'lr__C': [0.5]\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    gs_d2v_lr = GridSearchCV(pipe, param_grid=params, cv=2)\n",
    "    gs_d2v_lr.fit(X_train, y_train)\n",
    "    print('train score:', gs_d2v_lr.score(X_train, y_train))\n",
    "    print('test score:', gs_d2v_lr.score(X_test, y_test))\n",
    "    print('best score:', gs_d2v_lr.best_score_)\n",
    "    print('best params:', gs_d2v_lr.best_params_)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10d041f60>, 'model_dbow')\n",
      "train score: 0.8792161901702538\n",
      "test score: 0.8784131063283007\n",
      "best score: 0.8746653817325195\n",
      "best params: {'lr__C': 0.5, 'lr__penalty': 'l1'}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10cfa0860>, 'model_dm_mean')\n",
      "train score: 0.8543205910697077\n",
      "test score: 0.8599421779633794\n",
      "best score: 0.8492343934040048\n",
      "best params: {'lr__C': 0.5, 'lr__penalty': 'l1'}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a2ec36438>, 'model_dm_concat')\n",
      "train score: 0.6684334511189635\n",
      "test score: 0.6726630260199165\n",
      "best score: 0.6606703073134168\n",
      "best params: {'lr__C': 0.5, 'lr__penalty': 'l1'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    lr_model_func(X[model[1]], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model_func(X,y):\n",
    "    rf = RandomForestClassifier()\n",
    "    pipe = Pipeline([\n",
    "        ('rf', rf)\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'rf__n_estimators': [750],\n",
    "        'rf__max_features': ['log2', 'sqrt']\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    gs_d2v_rf = GridSearchCV(pipe, param_grid=params, cv=2)\n",
    "    gs_d2v_rf.fit(X_train, y_train)\n",
    "    print('train score:', gs_d2v_rf.score(X_train, y_train))\n",
    "    print('test score:', gs_d2v_rf.score(X_test, y_test))\n",
    "    print('best score:', gs_d2v_rf.best_score_)\n",
    "    print('best params:', gs_d2v_rf.best_params_)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10d041f60>, 'model_dbow')\n",
      "train score: 1.0\n",
      "test score: 0.8565692258271763\n",
      "best score: 0.8491273155584109\n",
      "best params: {'rf__max_features': 'log2', 'rf__n_estimators': 750}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10cfa0860>, 'model_dm_mean')\n",
      "train score: 1.0\n",
      "test score: 0.8295856087375522\n",
      "best score: 0.8222507763143806\n",
      "best params: {'rf__max_features': 'log2', 'rf__n_estimators': 750}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a2ec36438>, 'model_dm_concat')\n",
      "train score: 1.0\n",
      "test score: 0.6437520077096048\n",
      "best score: 0.6274761751793554\n",
      "best params: {'rf__max_features': 'sqrt', 'rf__n_estimators': 750}\n",
      "---\n",
      "CPU times: user 14min 21s, sys: 4.59 s, total: 14min 26s\n",
      "Wall time: 14min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    rf_model_func(X[model[1]], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_model_func(X,y):\n",
    "    grad = GradientBoostingClassifier()\n",
    "    pipe = Pipeline([\n",
    "        ('grad', grad)\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'grad__n_estimators': [1000],\n",
    "        'grad__max_features': ['log2']\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    gs_d2v_grad = GridSearchCV(pipe, param_grid=params, cv=2)\n",
    "    gs_d2v_grad.fit(X_train, y_train)\n",
    "    print('train score:', gs_d2v_grad.score(X_train, y_train))\n",
    "    print('test score:', gs_d2v_grad.score(X_test, y_test))\n",
    "    print('best score:', gs_d2v_grad.best_score_)\n",
    "    print('best params:', gs_d2v_grad.best_params_)\n",
    "#     print('classification report': \n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10d041f60>, 'model_dbow')\n",
      "train score: 0.9550273048506264\n",
      "test score: 0.8703822679087697\n",
      "best score: 0.863904058250348\n",
      "best params: {'grad__max_features': 'log2', 'grad__n_estimators': 1000}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x10cfa0860>, 'model_dm_mean')\n",
      "train score: 0.9393939393939394\n",
      "test score: 0.8469322197237391\n",
      "best score: 0.84023985437413\n",
      "best params: {'grad__max_features': 'log2', 'grad__n_estimators': 1000}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a2ec36438>, 'model_dm_concat')\n",
      "train score: 0.8306028482706928\n",
      "test score: 0.6636684869900418\n",
      "best score: 0.6396830495770425\n",
      "best params: {'grad__max_features': 'log2', 'grad__n_estimators': 1000}\n",
      "---\n",
      "CPU times: user 1min 39s, sys: 1.1 s, total: 1min 40s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    grad_model_func(X[model[1]], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When pairing the Doc2Vec models with classifiers, the two pairings that produced the best scores were Doc2Vec DBOW with logistic regression and Doc2Vec DBOW with gradient boost.  I decided to use the gradient boost classifier in my production model.  I made this decision because gradient boosting is an ensemble technique which means it has many different predictors trying to predict the same target variable, and as a boosting method, it adds one classifier at a time so that the next classifier is trained to improve the already trained ensemble.  Logistic regression is a linear classifier and is not equipped to make the types of decision that gradient boosting does.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
