{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a demonstration of how to apply the sentiment analysis model I have built.  I have imported 5732 tweets from the past week, all containing the hashtag #FirstMan (in reference to a movie that was recently released).  The tweets will be processed as follows:\n",
    "\n",
    "- They will be concatenated to the original movie review dataframe on the 'review' column\n",
    "- They will be preprocessed by the review_cleaner function \n",
    "- Doc2Vec will train its models on the entire new corpus (movie reviews + tweets) in order to build a new vector space\n",
    "- A gradient boost classifier will then train on these new vectors and will output a value of 'positive' or 'negative' when assessing the new tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import classification_report\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import utils\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/tweets_df', 'rb') as f:\n",
    "    tweets_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eaglesrising99</td>\n",
       "      <td>2018-10-18 03:49:26</td>\n",
       "      <td>Last chance! FOLLOW &amp;amp; RT for your chance t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdiWriter</td>\n",
       "      <td>2018-10-18 03:48:37</td>\n",
       "      <td>#DamienChazelle has given us his third excelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raulimartin</td>\n",
       "      <td>2018-10-18 03:48:00</td>\n",
       "      <td>Daily Box Office Top 7 for Tuesday, October 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dannysullivan</td>\n",
       "      <td>2018-10-18 03:47:38</td>\n",
       "      <td>Saw @FirstManMovie &amp;amp; even though I knew ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KeaneMexico</td>\n",
       "      <td>2018-10-18 03:46:18</td>\n",
       "      <td>Just been to see #FirstMan. Brilliant film. #R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                date  \\\n",
       "0  eaglesrising99 2018-10-18 03:49:26   \n",
       "1       AdiWriter 2018-10-18 03:48:37   \n",
       "2     Raulimartin 2018-10-18 03:48:00   \n",
       "3   dannysullivan 2018-10-18 03:47:38   \n",
       "4     KeaneMexico 2018-10-18 03:46:18   \n",
       "\n",
       "                                                text  \n",
       "0  Last chance! FOLLOW &amp; RT for your chance t...  \n",
       "1  #DamienChazelle has given us his third excelle...  \n",
       "2  Daily Box Office Top 7 for Tuesday, October 16...  \n",
       "3  Saw @FirstManMovie &amp; even though I knew ev...  \n",
       "4  Just been to see #FirstMan. Brilliant film. #R...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data into Pandas Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform all operations that were already done to original dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "df.drop(columns='Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df[df['type'] == 'train']\n",
    "df_train.reset_index(inplace=True)\n",
    "df_train.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['label'] != 'unsup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.drop_duplicates('review', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24904, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate tweets_df to df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.rename(columns = {'text':'review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24904, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5732, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, tweets_df, how='outer', on='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_3.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_4.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_1.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_1.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                             review label  \\\n",
       "0  train  Story of a man who has unnatural feelings for ...   neg   \n",
       "1  train  Airport '77 starts as a brand new luxury 747 p...   neg   \n",
       "2  train  This film lacked something I couldn't put my f...   neg   \n",
       "3  train  Sorry everyone,,, I know this is supposed to b...   neg   \n",
       "4  train  When I was little my parents took me along to ...   neg   \n",
       "\n",
       "          file user date  \n",
       "0      0_3.txt  NaN  NaT  \n",
       "1  10000_4.txt  NaN  NaT  \n",
       "2  10001_4.txt  NaN  NaT  \n",
       "3  10002_1.txt  NaN  NaT  \n",
       "4  10003_1.txt  NaN  NaT  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(columns=['type', 'file', 'user', 'date', 'user', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  Story of a man who has unnatural feelings for ...   neg\n",
       "1  Airport '77 starts as a brand new luxury 747 p...   neg\n",
       "2  This film lacked something I couldn't put my f...   neg\n",
       "3  Sorry everyone,,, I know this is supposed to b...   neg\n",
       "4  When I was little my parents took me along to ...   neg"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/data/edu/stanford/nlp/patterns/surface/stopwords.txt'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standford_nlp = soup.text.split('\\n')\n",
    "stop_word_list = standford_nlp + list(ENGLISH_STOP_WORDS) + ['film', 'films', 'movie', 'movies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "\n",
    "negations_dict = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dict.keys()) + r')\\b')\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def review_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped  = re.sub(r'@[A-Za-z0-9_]+', '', souped)\n",
    "    stripped = re.sub(r'https?://[^ ]+', '', stripped)\n",
    "    stripped = re.sub(r'www.[^ ]+', '', stripped)\n",
    "    lower_case = text.lower()\n",
    "    neg_dict = neg_pattern.sub(lambda x: negations_dict[x.group()], lower_case)\n",
    "    letters_only = re.sub('[^a-zA-Z]', \" \", neg_dict)\n",
    "    no_emoji = re.sub(emoji_pattern, '', letters_only)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train['review'] = df_train['review'].map(review_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story of man who has unnatural feelings for pi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airport starts as brand new luxury plane is lo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this film lacked something could not put my fi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorry everyone know this is supposed to be an ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when was little my parents took me along to th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  story of man who has unnatural feelings for pi...   neg\n",
       "1  airport starts as brand new luxury plane is lo...   neg\n",
       "2  this film lacked something could not put my fi...   neg\n",
       "3  sorry everyone know this is supposed to be an ...   neg\n",
       "4  when was little my parents took me along to th...   neg"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_documents = []\n",
    "for indx, doc in enumerate(df_train[\"review\"].values):\n",
    "    tagged_documents.append(TaggedDocument([x for x in doc.split()], [indx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "vec_size = 150\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, dbow_words=1, vector_size=vec_size, negative=5, hs=0, min_count=2, sample=0, \n",
    "             workers=cores)\n",
    "\n",
    "model_dm_mean = Doc2Vec(dm=1, dm_mean=1, vector_size=vec_size, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "                workers=cores, alpha=0.05, comment='alpha=0.05')\n",
    "\n",
    "model_dm_concat = Doc2Vec(dm=1, dm_concat=1, vector_size=vec_size, window=5, negative=5, hs=0, min_count=2, sample=0, \n",
    "                  workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d150,n5,w5,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d150,n5,w5,mc2,t4) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "models = [(model_dbow, 'model_dbow'), (model_dm_mean, 'model_dm_mean'), (model_dm_concat, 'model_dm_concat')]\n",
    "\n",
    "for model in models:\n",
    "    model[0].build_vocab(tagged_documents)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model[0])\n",
    "    \n",
    "models_by_name = OrderedDict((str(model[1]), model[0]) for model in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 1 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 2 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 3 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 4 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 5 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 6 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 7 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 8 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 9 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 10 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 11 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 12 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 13 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 14 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 15 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 16 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 17 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 18 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 19 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 20 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 21 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 22 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 23 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 24 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 25 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 26 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 27 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 28 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 29 Model: Doc2Vec(dbow+w,d150,n5,w5,mc2,t4)\n",
      "Epoch: 0 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 1 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 2 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 3 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 4 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 5 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 6 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 7 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 8 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 9 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 10 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 11 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 12 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 13 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 14 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 15 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 16 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 17 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 18 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 19 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 20 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 21 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 22 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 23 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 24 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 25 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 26 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 27 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 28 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 29 Model: Doc2Vec(\"alpha=0.05\",dm/m,d150,n5,w10,mc2,t4)\n",
      "Epoch: 0 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 1 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 2 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 3 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 4 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 5 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 6 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 7 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 8 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 9 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 10 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 11 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 12 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 13 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 14 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 15 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 16 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 17 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 18 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 19 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 20 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 21 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 22 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 23 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 24 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 25 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 26 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 27 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 28 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n",
      "Epoch: 29 Model: Doc2Vec(dm/c,d150,n5,w5,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for epoch in range(30):\n",
    "        print('Epoch: {0}'.format(epoch), 'Model: %s' % (model[0]))\n",
    "        model[0].train(utils.shuffle(tagged_documents), total_examples=len(tagged_documents), epochs=1)\n",
    "        model[0].alpha -= 0.002\n",
    "        model[0].min_alpha = model[0].alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = {}\n",
    "\n",
    "for model in models:\n",
    "    X[model[1]] = np.zeros((df_train.shape[0], vec_size))\n",
    "    for i in range(df_train.shape[0]):\n",
    "        X[model[1]][i] = model[0].docvecs[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_train['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_model_func(X,y):\n",
    "    grad = GradientBoostingClassifier()\n",
    "    pipe = Pipeline([\n",
    "        ('grad', grad)\n",
    "    ])\n",
    "    \n",
    "    params = {\n",
    "        'grad__n_estimators': [1000],\n",
    "        'grad__max_features': ['log2']\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "    gs_d2v_grad = GridSearchCV(pipe, param_grid=params, cv=2)\n",
    "    gs_d2v_grad.fit(X_train, y_train)\n",
    "    print('train score:', gs_d2v_grad.score(X_train, y_train))\n",
    "    print('test score:', gs_d2v_grad.score(X_test, y_test))\n",
    "    print('best score:', gs_d2v_grad.best_score_)\n",
    "    print('best params:', gs_d2v_grad.best_params_)\n",
    "    print('---')\n",
    "    return gs_d2v_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a367245c0>, 'model_dbow')\n",
      "train score: 0.9557233108469858\n",
      "test score: 0.8721490523610665\n",
      "best score: 0.8663668486990042\n",
      "best params: {'grad__max_features': 'log2', 'grad__n_estimators': 1000}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a36724518>, 'model_dm_mean')\n",
      "train score: 0.9405717956954706\n",
      "test score: 0.8475746867973016\n",
      "best score: 0.8380447585394581\n",
      "best params: {'grad__max_features': 'log2', 'grad__n_estimators': 1000}\n",
      "---\n",
      "(<gensim.models.doc2vec.Doc2Vec object at 0x1a367246d8>, 'model_dm_concat')\n",
      "train score: 0.8231609380019274\n",
      "test score: 0.6553164150337295\n",
      "best score: 0.6226041332048399\n",
      "best params: {'grad__max_features': 'log2', 'grad__n_estimators': 1000}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    m = grad_model_func(X[model[1]][:24904,:], y[:24904])\n",
    "    grad_model[model[1]+'_trained'] = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new data frame with all new rows that have import tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "      <th>textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last chance follow amp rt for your chance to w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damienchazelle has given us his third excellen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily box office top for tuesday october astar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saw firstmanmovie amp even though knew everyth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just been to see firstman brilliant film richa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label predicted  textblob\n",
       "0  last chance follow amp rt for your chance to w...   NaN       pos       NaN\n",
       "1  damienchazelle has given us his third excellen...   NaN       pos       NaN\n",
       "2  daily box office top for tuesday october astar...   NaN       pos       NaN\n",
       "3  saw firstmanmovie amp even though knew everyth...   NaN       pos       NaN\n",
       "4  just been to see firstman brilliant film richa...   NaN       pos       NaN"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_train.iloc[24904:].reset_index(drop=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column 'predicted' that will contain a prediction of positive or negative for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train['predicted'] = grad_model['model_dbow_trained'].predict(X[models[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a count of all predicted positive and negative tweets analyzed by my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count = 4816\n",
      "Negative count = 916\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "neg_count = 0\n",
    "\n",
    "for score in df_train.loc[24904:, 'predicted']:\n",
    "    if score ==  'pos':\n",
    "        pos_count += 1\n",
    "    if score == 'neg':\n",
    "        neg_count += 1\n",
    "        \n",
    "print(\"Positive count = {}\".format(pos_count))\n",
    "print(\"Negative count = {}\".format(neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob and VADER Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TextBlob.sentiment to all columns with tweets and designate output to new column (TextBlob.sentiment is scored on a scale of -1 to 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new['textblob'] = df_new['review'].apply(lambda x: TextBlob(x).polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "      <th>textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last chance follow amp rt for your chance to w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damienchazelle has given us his third excellen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daily box office top for tuesday october astar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saw firstmanmovie amp even though knew everyth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just been to see firstman brilliant film richa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label predicted  textblob\n",
       "0  last chance follow amp rt for your chance to w...   NaN       pos      0.40\n",
       "1  damienchazelle has given us his third excellen...   NaN       pos      0.50\n",
       "2  daily box office top for tuesday october astar...   NaN       pos      0.25\n",
       "3  saw firstmanmovie amp even though knew everyth...   NaN       pos      0.50\n",
       "4  just been to see firstman brilliant film richa...   NaN       pos      0.90"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a count of all positive, neutral and negative tweets analyzed by TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count = 3715\n",
      "Negative count = 717\n",
      "Neutral count = 1300\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "neg_count = 0\n",
    "neutral_count = 0\n",
    "\n",
    "for score in df_train['textblob']:\n",
    "    if score > 0:\n",
    "        pos_count += 1\n",
    "\n",
    "\n",
    "for score in df_train['textblob']:\n",
    "    if score < 0:\n",
    "        neg_count += 1\n",
    "\n",
    "\n",
    "for score in df_train['textblob']:\n",
    "    if score == 0:\n",
    "        neutral_count += 1\n",
    "\n",
    "print(\"Positive count = {}\".format(pos_count))\n",
    "print(\"Negative count = {}\".format(neg_count))\n",
    "print(\"Neutral count = {}\".format(neutral_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SentimentIntensityAnalyzer.polarity_scores to all columns with tweets and designate the ouput to a new column (Vader sentiment is scored on a scale of -4 to 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vs = analyzer.polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new['vader_sentiment'] = df_new['review'].apply(lambda x: vs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count = 3321\n",
      "Negative count = 1007\n",
      "Neutral count = 1404\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "neg_count = 0\n",
    "neutral_count = 0\n",
    "\n",
    "for dictionary in df_new.loc[:, 'vader_sentiment']:\n",
    "    if dictionary['compound'] > 0:\n",
    "        pos_count += 1\n",
    "    elif dictionary['compound'] < 0:\n",
    "        neg_count += 1\n",
    "    else:\n",
    "        neutral_count += 1 \n",
    "\n",
    "print(\"Positive count = {}\".format(pos_count))\n",
    "print(\"Negative count = {}\".format(neg_count))\n",
    "print(\"Neutral count = {}\".format(neutral_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Count df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>my_model</th>\n",
       "      <td>4816</td>\n",
       "      <td>916</td>\n",
       "      <td>XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob</th>\n",
       "      <td>3715</td>\n",
       "      <td>717</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vader_sentiment</th>\n",
       "      <td>3321</td>\n",
       "      <td>1007</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 positive  negative neutral\n",
       "my_model             4816       916     XXX\n",
       "textblob             3715       717    1300\n",
       "vader_sentiment      3321      1007    1404"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = ['my_model', 'textblob', 'vader_sentiment']\n",
    "s = {'positive': [4816, 3715, 3321], 'negative': [916, 717, 1007], 'neutral': ['XXX', 1300, 1404]}\n",
    "\n",
    "pd.DataFrame(data=s, index=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
